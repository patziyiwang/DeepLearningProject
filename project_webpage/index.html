<!DOCTYPE html>
<html lang="en"><head>  
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Deep Learning Class Project
  | Georgia Tech | Fall 2018: CS 4803 / 7643</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

<!-- Le styles -->  
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>
  
<link href="css/bootstrap-responsive.min.css" rel="stylesheet">
</head>

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name --> 
<h1>Obstacle Dynamics Prediction</h1> 
<span style="font-size: 20px; line-height: 1.5em;"><strong>Ziyi Wang</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">Fall 2018 CS 4803 / 7643 Deep Learning: Class Project</span><br>
<span style="font-size: 18px; line-height: 1.5em;">Georgia Tech</span>
<hr>

This webpage template is based on a similar template from Dr. Devi Parikh's
<a href="https://samyak-268.github.io/F18CS4476/">Intro to Computer Vision course</a>.

<!-- Goal -->
<h2>Abstract</h2>

The problem we try to tackle in this project is obstacle movement prediction, which is essential to research on autonomous driving with only visual information. We split the problem into two parts: first identify the obstacle by drawing a bounding box around it, then predict its movements by focusing on the bounding box dynamics instead of the whole image. One or two sentences on the main result you obtained.
<br><br>
<!-- figure -->
<h2>Teaser figure</h2>
A flowchart like figure showing how we take an input image, draws a bounding box and predicts its movements. (This one is from <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">AlexNet</a>.)
<br><br>
<!-- Main Illustrative Figure --> 
<div style="text-align: center;">
<img style="height: 200px;" alt="" src="images/alexnet.png">
</div>

<br><br>
<!-- Introduction -->
<h2>Introduction / Background / Motivation</h2>
In this project, we work on predicting the movments of one or more obstacles captured in a video. This is an essential part of research on autonomous driving since most applications today require various sensors like LIDAR, stereo camera, GPS, etc, which are very expensive. The ability to predict obstacle movements in real time with only single/multiple cameras would greatly expedite the progress of visual based autonomous driving.
<br>
The current researh on autonomous driving focuses on the prediction of entire images. The limits with this approach are twofold: it is very difficult to predict very far into the future with high fidelity in real time, and it also wastes computation on prediction of the background, which might not be required in the path planning and control module.

<h4>What did you try to do? What problem did you try to solve? Articulate your objectives using absolutely no jargon.</h4>
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.

<h4>How is it done today, and what are the limits of current practice?</h4>
Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.

<h4>Who cares? If you are successful, what difference will it make?</h4>
Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.

<br><br>
<!-- Approach -->
<h2>Approach</h2>
<h4>What did you do exactly? How did you solve the problem? Why did you think it would be successful? Is anything new in your approach?</h4>
<ul>
  <li><b>Tracking</b></li>
  We first tried a set of state of the art object tracker based on AdaBoost, Multiple Instance Learning, Kernelized Correlation Filters, and GOTURN. These tracker performs quite decent when there is not much occlusion. However, if we encounter only slight occlusion, all of the abovementioned tracker failed. 
  <li><b>Dynamics prediction</b></li>
</ul>

<h4>What problems did you anticipate? What problems did you encounter? Did the very first thing you tried work?</h4>
<ul>
  <li><b>Tracking</b></li>
  We turn our focus to study more recent development of object tracking with deep learning techniques anticipating more statble object box tracking. We found ECO(Efficient Convolution Operators for Tracking) out ferformed all the trackers we had tried previously and satisfied our requirement for box tracking so that we can previde a stable tracker for our next steps of dynamics prediciton.

  <li><b>Dynamics prediction</b></li>
</ul>
<br><br>

<h2>ECO: Efficient Convolution Operators for Tracking</h2>
<h3>
  <ol>
  <li>Factorized Convolution Operator</li>
  <li>Generative Sample Space Model</li>
  <li>Model Update Strategy</li>
  </ol>
</h3>

<!-- Results -->
<h2>Experiments and Results</h2>
<h4>How did you measure success? What experiments were used? What were the results, both quantitative and qualitative? Did you succeed? Did you fail? Why?</h4>
Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt.

<br><br>

<!-- Main Results Figure --> 
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="images/results.png">
</div>
<br><br>

  <hr>
  <footer> 
  <p>Â© Ziyi Wang</p>
  </footer>
</div>
</div>

<br><br>

</body></html>
