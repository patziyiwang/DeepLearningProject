<!DOCTYPE html>
<html lang="en"><head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Deep Learning Class Project
  | Georgia Tech | Fall 2018: CS 4803 / 7643</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

<!-- Le styles -->
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>

<link href="css/bootstrap-responsive.min.css" rel="stylesheet">
</head>

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name -->
<h1>Obstacle Dynamics Prediction</h1>
<span style="font-size: 20px; line-height: 1.5em;"><strong>Ziyi Wang</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">Fall 2018 CS 4803 / 7643 Deep Learning: Class Project</span><br>
<span style="font-size: 18px; line-height: 1.5em;">Georgia Tech</span>
<hr>

This webpage template is based on a similar template from Dr. Devi Parikh's
<a href="https://samyak-268.github.io/F18CS4476/">Intro to Computer Vision course</a>.

<!-- Goal -->
<h2>Abstract</h2>

  The problem we try to tackle in this project is obstacle movement prediction, which is essential to research on autonomous driving with only visual information. We split the problem into two parts: first identify the obstacle by drawing a bounding box around it, then predict its movements by focusing on the bounding box dynamics instead of the whole image. One or two sentences on the main result you obtained.
<br><br>
<!-- figure -->
<h2>Teaser figure</h2>
A flowchart like figure showing how we take an input image, draws a bounding box and predicts its movements. (This one is from <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">AlexNet</a>.)
<br><br>
<!-- Main Illustrative Figure -->
<div style="text-align: center;">
<img style="height: 200px;" alt="" src="images/alexnet.png">
</div>

<br><br>
<!-- Introduction -->
<h2>Introduction / Background / Motivation</h2>
<h4>What did you try to do? What problem did you try to solve? Articulate your objectives using absolutely no jargon.</h4>
  In this project, we work on predicting the movments of one or more obstacles captured in a video. We try to do so by first applying an object detector/tracker which draws bounding boxes around obstacles of interest. We then predict the movements and shrinking/expanding of the bounding boxes, which reflect the dynamics of the obstacles. In the proeject we tackle this problem in the context of autonomous driving, where we use videos taken by a car-mounted camera and try to predict movements of other cars in the video.

<h4>How is it done today, and what are the limits of current practice?</h4>
  Most of the applications in obstacle detection/avoidance for autonomous driving rely on various sensors like LIDAR, sereo cameras, GPS, etc. (reference), which are very expensive and require an algorithm to make sense of and fuse all the sensor information. In certain applications, such as driving off road, it might be infeasible to access many sensors.
  In the field of video prediction research, there are many efforts on predicting entire images. However, predicting videos far into the future in real time has not been very successful, even with advanced network architecture and training scheme (reference). Another approach to video prediction leverages attention where only certain areas in an image are predicted while the rest remains still. The limit of this this approach is the assumption of a still background which does not hold in the autonomous driving setting.
  <br>


<h4>Who cares? If you are successful, what difference will it make?</h4>
  The success of this project is important for future research on obstacle avoidance in autonomous driving with only visual information. The output of the pipeline resulted from this project can be postprocessed by another module to estimate the obstacle location and size, which can then be used by a path planner. This would allow for a framework capable of 

<br><br>
<!-- Approach -->
<h2>Approach</h2>
<h4>What did you do exactly? How did you solve the problem? Why did you think it would be successful? Is anything new in your approach?</h4>

  We broke the problem into two parts: obstacle detection/tracking and obstacle dynamics prediction. For the tracking part we turned to existing obstacle detection algorithms since there are plenty of existing work in this field.
  <ul>
  <li><b>Tracking</b></li>
  We first tried a set of state of the art object tracker based on AdaBoost, Multiple Instance Learning, Kernelized Correlation Filters, and GOTURN. These tracker performs quite decent when there is not much occlusion. However, if we encounter only slight occlusion, all of the abovementioned tracker failed.
  <li><b>Obstacle Dynamics Prediction</b></li>
  For obstacle dynamics prediction we used
</ul>

<h4>What problems did you anticipate? What problems did you encounter? Did the very first thing you tried work?</h4>
<ul>
  <li><b>Tracking</b></li>
  We turn our focus to study more recent development of object tracking with deep learning techniques anticipating more statble object box tracking. We found ECO(Efficient Convolution Operators for Tracking) out ferformed all the trackers we had tried previously and satisfied our requirement for box tracking so that we can previde a stable tracker for our next steps of dynamics prediciton.

  <li><b>Dynamics prediction</b></li>
</ul>
<br><br>

<h2>ECO: Efficient Convolution Operators for Tracking</h2>
<h3>
  <ol>
  <li>Factorized Convolution Operator</li>
  <li>Generative Sample Space Model</li>
  <li>Model Update Strategy</li>
  </ol>
</h3>

<!-- Results -->
<h2>Experiments and Results</h2>

<h4>How did you measure success? What experiments were used? What were the results, both quantitative and qualitative? Did you succeed? Did you fail? Why?</h4>
Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt.

<br><br>

<!-- Main Results Figure -->
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="images/results.png">
</div>
<br><br>

  <hr>
  <footer>
  <p>Â© Ziyi Wang</p>
  </footer>
</div>
</div>

<br><br>

</body></html>
